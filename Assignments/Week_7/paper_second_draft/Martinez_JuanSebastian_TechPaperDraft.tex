\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2016}

\usepackage[final, nonatbib]{nips_2016}

% to compile a camera-ready version, add the [final] option, e.g.:
%\usepackage[final]{nips_2016}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

% My packages
\usepackage{amsmath}        %Matrix
\usepackage{graphicx}       %Graphics
\usepackage{subcaption}     %Subfigures


\title{Design Optimization of a Stochastic Multi-Objective Problem: \\Gaussian Process Regressions for Objective Surrogates}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Juan S. Martinez\\
  Department of Electrical and Electronic Engineering\\
  Universidad de los Andes\\
  Bogot√°, Colombia \\
  \texttt{js.martinez777@uniandes.edu.co} \\
  \And
  Piyush Pandita \\
  School of Mechanical Engineering \\
  Purdue University \\
  West Lafayette, Indiana 47907\\
  \texttt{ppandit@purdue.edu} \\
  \AND
  Ilias Bilionis \\
  School of Mechanical Engineering \\
  Purdue University \\
  West Lafayette, Indiana 47907\\
  \texttt{ibilion@purdue.edu} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
    Global optimization of expensive, multi-modal and noisy multi-objective functions is a common problem that comes up frequently in various areas of computational and experimental research. Along with being expensive to evaluate and noisy, we are also particularly interested in cases where the objective function under consideration is a black box and does not provide gradient information of the quantity of interest (QoI) with reference to the inputs. Because of the high cost of every single evaluation of such objective functions, we can only obtain a limited number of evaluations. This necessarily induces epistemic uncertainty (lack of knowledge due to limited data) on our problem. The Bayesian approach provides a natural framework to tackle this problem, building Gaussian process surrogates that model the objective functions and allow a sequential optimization process. The method applies the expected improvement (EI) information acquisition function in each iteration to perform an efficient global optimization (EGO) and discover the Pareto front of the problem, which contains the set of optimal solutions of the objectives. We implemented this method in a NanoHUB tool and tested it with synthetic examples and real observations of an expensive experiment, where it proved to be efficient in finding the corresponding set of optimal solutions for each problem. This methodology demonstrates how the efficiency of the Bayesian approach for handling epistemic uncertainty in multi-objective optimization problems, dealing with limited observations and avoiding a high amount of evaluations of time-consuming codes or expensive experiments.
\end{abstract}

\section{Introduction}

A great variety of problems in science and engineering can be expressed as optimization problems, where a function that describes the operation of a system should be minimized or maximized, restricted to some constraints imposed by the system itself. For example, a supermarket may want to minimize its inventory purchases while keeping enough stock for its operation, or in a metal-forming shop, a manufacturer may want to maximize the performance of the manufacturing system adjusting certain parameters, like the forming temperature and the die geometry \cite{Huang2006}. Moreover, real optimization problems do not have trivial solutions, since in many cases the optimization could target: black-box systems where the physics and mathematics of the process are not well known; expensive simulations or evaluations of objective functions \cite{Jones1998}; introduction of uncertainty at the output due to noise in the input data; and multiple objectives. In this context, a need for the design of a method for solving stochastic multi-objective optimization problems arises and becomes important in the science and engineering community.\\

A typical problem in experimental research is to determine the parameters of an experiment that can maximize or minimize some output quantity. There could be inadequate knowledge of the physics of the underlying problem. The experiment may also be expensive (computationally or financially) and thus may only be performed under a limited number of times under a finite budget. Such problems are well suited to be treated as Bayesian global optimization problems where limited output observations are used to build a model that could describe the system with the highest accuracy possible. Optimization under these circumstances has been approached from different perspectives, for example, advances in efficient global optimization of expensive simulations have been made through the analysis of various criteria of the problem, like the expected improvement (EI) of running the simulation at a particular point; also, stopping criteria for the sequential optimization processes that rules black-box problems have also been developed \cite{Jones1998}, as well as curiosity-driven techniques \cite{Schaul2011}. In this matter, the structure for solving black-box optimization problems is based on building response surfaces over observed data. The taxonomy of this process includes the use of different criteria to evaluate the sequential process of optimization, in which the EI information acquisition scheme has proven to be more efficient than any other criteria, including the probability of improvement and lower and upper confidence bounds \cite{Jones2001}.\\

This study shows how black-box systems have been approached in order to perform a sequential process of optimization. However, dealing with a black-box system is only one of the many problems optimization faces in real scientific and engineering scenarios. Another major issue corresponds to the effect of epistemic uncertainty, noise in the input data, and how it propagates in the surrogate models used in optimization. For this problem, the use of Gaussian process regression has become a very useful and effective strategy to generate a stochastic approach for the problem \cite{Wang2016}, modifying the EI criteria and considering Bayesian models to manipulate efficient global optimization schemes, as presented in \cite{Huang2006}, \cite{Pandita2016} and \cite{Li2014}. Stochastic approaches to optimization problems often require the development and implementation of probabilistic machine learning techniques, which are fully developed tools as documented by Seeger \cite{Seeger2004} and Davidson-Pilon \cite{Davidson-Pilon2014}. Although developed tools and models for optimization form the state of the art of stochastic optimization, other great issue arises in the systems studied so far, which is the problem of targeting multiple objectives inside the same system.\\

Multi-objective optimization (MOO) problems are widely studied through different techniques, which include the application of genetic algorithms through the application of evolutionary strategies \cite{Costa2006}. In MOO problems, genetic algorithms are used to obtain the Pareto front, which contains the optimal solutions to the problem under consideration. Also, evolutionary techniques have been developed to solve expensive simulation-based optimization problems as presented in \cite{Guo2007} and \cite{Huang2009}. Although these techniques address MOO problems, they do not deal with epistemic uncertainty. On the other hand, these types of considerations have been made, and they show how MOO problems can be addressed by an extension of the EI criteria, deriving a closed form of the information acquisition function \cite{wagner2010expected}. Within this context, the study presented here aims to develop a "greedy" and reliable method for MOO problems for real black-box systems, addressing uncertainty propagation and considering expensive objective function evaluations through Gaussian process regression surrogates.\\

The method relies on Gaussian process regressions to build surrogates for the objective functions of the system, as an approximation of the functions that map the inputs to the corresponding outputs. This surrogates are able to consider uncertainty at the input and enables the addition of observations to enrich prior beliefs of the problem, in order to adjust the response surfaces and obtain a better description of the system.\\

Section 2 describes the methodology of these Gaussian process regressions and section 3 presents the results of the sequential optimization process using the surrogates. Section 4 discusses the results obtained for the synthetic example and the real test example and section 5 presents the conclusions of this work.

\section{Methodology}

The MOO problem of black-box systems was addressed through a Bayesian approach, where initial observations of the experiments we want to model provide information that enrich prior beliefs and help us determine better surrogates for our objectives. As only limited information is available, Gaussian process regression was used as a technique for building the functions, this method is able to quantify the epistemic uncertainty induced by the reduced amount of observations.

A Gaussian process (GP) is a collection of random variables, any finite number of which have a joint Gaussian distribution\cite{Seeger2004}. It represents a generalization of a multivariate Gaussian distribution to infinite dimensions, over a space of functions. A GP is defined by its mean function $m(\vec{x})$ and covariance function $k(\vec{x},\vec{x}')$; they are defined for a process $f(\vec{x})$ as:

\begin{equation}
    m(\vec{x}) = \mathbb{E}[f(\vec{x})],
\end{equation}
\begin{equation}
    k(\vec{x},\vec{x}') = \mathbb{E}[(f(\vec{x})-m(\vec{x}))(f(\vec{x}')-m(\vec{x}'))].
\end{equation}

Then, the process is defined as a Gaussian process as: \cite{Seeger2004}

\begin{equation}
    f(\vec{x}) \sim GP(m(\vec{x}), k(\vec{x},\vec{x}')).
\end{equation}

In a more general case, the mean and covariance functions depend on a set of \textit{hyperparameters} denoted by $\vec{\theta}$. Taking this into account, a Gaussian process could be defined as:

\begin{equation}
    f(\cdot)|\vec{\theta} \sim GP(f(\cdot)|m(\cdot;\vec{\theta}),k(\cdot,\cdot;\vec{\theta})).
\end{equation}

As for the Bayesian approach taken in this study, a GP was used to model our prior beliefs about the objective functions in the system. In this case, all information about the mean can be included in the covariance function. Thus, $m(\cdot;\vec{\theta})$ was taken to be zero. On the other hand, the covariance function used was the squared exponential (SE) covariance:

\begin{equation}
    k(\vec{x},\vec{x}';\vec{\theta}) = s^2 \exp \left \{ -\frac{1}{2}\sum_{i=1}^{d}\frac{(x_i - x_i')^2}{\ell_i^2} \right \},
\end{equation}

where $d$ is the dimensionality of the input space, $s > 0$ is the signal strength of the response and $\ell_i > 0$ is the lengthscale along the input dimension $i$. For this case, the set of hyperparameters $\vec{\theta}$ is composed as $\vec{\theta} = \{s, \ell_1, \ldots, \ell_d\}$. This design for the mean function and the covariance function is the same as the approach taken in \cite{Pandita2016}.\\

In the Gaussian process regression, noisy and limited observations provide a likelihood of the data subject to the hyperparameters of the model. Assuming a Gaussian noise with unknown variance $\sigma^2$, the likelihood is\cite{Pandita2016}:

\begin{equation}
    p(\vec{y}_{1:n}|\vec{x}_{1:n}, \vec{\psi}) = \mathcal{N}(\vec{y}_{1:n}|\vec{f}_{1:n},\textbf{K}_n(\vec{\theta}) + \sigma^2\textbf{I}_n).
    \label{likelihood}
\end{equation}

As expressed in equation \ref{likelihood}, the likelihood has the PDF of a multivariate normal random variable with mean $\vec{f}_{1:n}$ and covariance matrix $\textbf{K}_n(\vec{\theta}) + \sigma^2\textbf{I}_n$, where $\textbf{I}_n \in \mathbb{R}^{n\times n}$ is the identity matrix, $\vec{\psi} = \{ \vec{\theta}, \sigma \} $ and $\textbf{K}_n \in \mathbb{R}^{n\times n}$ is the covariance matrix of the form:

\begin{equation}
    \textbf{K}_n(\vec{\theta}) =
    \begin{bmatrix}
        k(\vec{x}_1,\vec{x}_1;\vec{\theta}) & \cdots & k(\vec{x}_1,\vec{x}_n;\vec{\theta}) \\
        \vdots & \ddots & \vdots\\
        k(\vec{x}_n,\vec{x}_1;\vec{\theta}) & \cdots & k(\vec{x}_n,\vec{x}_n;\vec{\theta})
    \end{bmatrix}.
\end{equation}

Through Bayes rule, combining the prior beliefs and the likelihood of observed data produces a posterior distribution of the function space that represents our model. This distribution is described as\cite{Pandita2016}:

\begin{equation}
    p(f(\cdot)|\vec{x}_{1:n},\vec{y}_{1:n},\vec{\psi}) = GP(f(\cdot)|m_n(\vec{x};\vec{\psi}),k_n(\vec{x},\vec{x}';\vec{\psi})),
\end{equation}

where $m_n(\vec{x};\vec{\psi})$ and $k_n(\vec{x},\vec{x}';\vec{\psi})$ are the posterior mean and covariance functions, their analytical expressions can be found in \cite{Pandita2016}. With this in mind, the common procedure to adjust the posterior model is to maximize the logarithm of the likelihood\footnote{Maximizing the likelihood often requires unachievable computational resources, instead, the logarithm of the function has the same behavior and it demands more reasonable computation requirements}, which produces the corresponding hyperparameters that optimize the model.\\

To illustrate this, figure \ref{gp_regression} shows a Gaussian process regression for a cosine function with Gaussian noise added, the regression was built with a signal strength of 1 and a lengthscale of 1 for the 1-dimensional input. The "X" marks represent sample points of the real function and the continuous line represents the mean function of the sampled regression, along with the shaded area that represents the uncertainty of the surrogate. In figure \ref{gp}, only prior information is used to build the regression, but on figure \ref{gp_optimized}, observed data is applied and the posterior is adjusted due to the maximization of the likelihood of data. As we can see, uncertainty is reduced around the observed data but increases around isolated data points or where there are no observations.

\begin{figure}
\centering
	\begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{gp_cosine.png}
        \caption{Gaussian process regression}
        \label{gp}
	\end{subfigure}
    \hfill
	\begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{gp_cosine_optimized.png}
	    \caption{Optimized Gaussian process regression}
	    \label{gp_optimized}
	\end{subfigure}
\caption{Gaussian process regression of cosine function}
\label{gp_regression}
\end{figure}

This methodology applies for a single objective but can be extended to multiple outputs, and a sequential optimization algorithm for multi-objective problems can be implemented. This is the case for the overall project, where a sequential algorithm uses an extension of the expected improvement as the best information acquisition function (IAF)\cite{Jones2001} (applied to multiple objectives \cite{wagner2010expected}) to generate new evaluations of the experiment that is being modeled.

\section{Results}

To test the developed method, a nanoHUB tool was created, where initial observations were loaded into a Python program that executed the optimization algorithm. The tool allows an iterative process where the user can implement the experimental designs that the tool suggests, in order to input the results to the tool and continue the process of obtaining the optimal designs for the expensive experiment being studied. Figure \ref{tool} shows this tool, named SMOOT (Stochastic Multi-Objective Optimization Tool) after its general purpose.\\

\begin{figure}
\centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{tool1}
        \caption{Interface for initial observations}
        \label{tool_1}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{tool2}
        \caption{Interface for iterative optimization process}
        \label{tool_2}
    \end{subfigure}
\caption{SMOOT tool: a) Interface to input initial observations. b) Interface to input new results from proposed experiments}
\label{tool}
\end{figure}

As a first result, a synthetic two-dimensional function was tested in two scenarios. In both cases, the generated and ideal Pareto fronts where obtained and compared; first, with a set of 2 initial observations and 20 iterations, and then with a set of 10 initial observations and just 10 iterations.\\

The synthetic example describes two functions, $f_1(\vec{x})$ and $f_2(\vec{x})$ \cite{parr2013improvement}:

\begin{equation}\label{f1}
    f_1(\vec{x}) = \left( b_2 - \cfrac{5.1}{4\pi^2}b_1^2 + \cfrac{5}{\pi}b_1 - 6 \right)^2 + 10\left[ \left( 1 - \cfrac{1}{8\pi} \right)\cos(b_1) + 1 \right],
\end{equation}
\begin{multline}\label{f2}
    f_2(\vec{x}) = - \sqrt{(10.5-b_1)(b_1+5.5)(b_2+0.5)} - \cfrac{1}{30}\left( b_2 - \cfrac{5.1}{4\pi^2}b_1^2 - 6 \right)^2\\ - \cfrac{1}{3}\left[ \left( 1 - \cfrac{1}{8\pi} \right)\cos(b_1) + 1 \right],
\end{multline}

where $b_1 = 15x_1 - 5$ and $b_2 = 15x_2$. In this case, a slight modification was made to the functions in order to add noise to the input data, so that $x_1$ and $x_2$ are defined as:

\begin{align*}
    x_1 = x_1' + \epsilon\\
    x_2 = x_2' + \epsilon\\
    x_1', x_2' \in \left[0,1\right]\\
    \epsilon \sim \mathcal{N}(0,\sigma^2)
\end{align*}

\begin{figure}[!t]
\centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{li_ex1_00}
        \caption{Initial Pareto front for 2 initial observations}
        \label{li_initial}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{hi_ex1_00}
        \caption{Initial Pareto front for 10 initial observations}
        \label{hi_intial}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{li_ex1_19}
        \caption{Final Pareto front for 2 initial observations}
        \label{li_final}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{hi_ex1_09}
        \caption{Final Pareto front for 10 initial observations}
        \label{hi_final}
    \end{subfigure}
\caption{Initial Pareto fronts for the synthetic examples: a) First Pareto front with just 2 initial observations. b) First Pareto front with 10 initial observations. c) Final Pareto front with just 2 initial observations after 20 iterations. d) Final Pareto front with 10 initial observations after 10 iterations}
\label{fronts}
\end{figure}

Figure~\ref{fronts} shows the Pareto fronts for the two test cases at the first and last iteration. In the figure, the rhombus represent the points selected to be part of the front, the circled point is the point added to the front in that specific iteration and the bold line is what is estimated as the true Pareto front of the problem. Figures \ref{li_initial} and \ref{hi_intial} show the initial state of the Pareto fronts at the first iteration of both cases, and figures \ref{li_final} and \ref{hi_final} show the final state of the Pareto front after the corresponding number of iterations in both cases. To generate this plots, the two dimensional functions (\ref{f1}) and (\ref{f2}) where evaluated for every experiment proposed by the tool, produced after every iteration of the optimization algorithm. The result of the functions where introduced into the tool to continue the iterative process and obtain a new experiment proposal for the functions.

\section{Discussion}

The results shown in figure \ref{fronts} demostrate how the method is able to discover the Pareto front through an iterative process. As also shown in \cite{Huang2006}, it reinforces the usage of Gaussian process regression surrogates to extend the EGO algorithm, along with other extensions (the usage of newly developed EI due to its efficiency \cite{Jones1998}) to succesfully solve the optimization problem under uncertainty.\\

Figure \ref{li_initial} shows how few initial observations generate a not very significant Pareto front, although its points are close to the ideal curve. On the other hand, figure \ref{hi_intial} shows that a bigger amount of observations generate a more accurate set up, as there is more information available to generate a better posterior for the surrogates of the model.\\

Figures \ref{li_final} and \ref{hi_final} show how the number of initial observations has a significant impact on the required number of iterations for a sufficient solution. Considering that both cases produce a similar Pareto front, the figures illustrate that few initial observations require the double amount of iterations, compared to the case of high initial data. This result can be taken as a consideration at the time of gathering initial experimental data, it can be said that more observations produce better results with less iterations. This is a consequence of the Bayesian inference used to handle the problem, as a bigger amount of information reduces uncertainty in the Gaussian process surrogates and enables more accurate models, which represent the objective functions being optimized.\\

This result has to be interpreted carefully, as the methodology proposed aims to solve optimization problems for expensive experiments or simulation codes, so gathering a big amount of initial observations can have a very high cost, which is contrary to the goal of this study. In this context, as long as it is reasonable, it is recommended that a high amount of initial data is entered to the tool to generate better results in a short time.\\

Considering the tool performance, the simulation times changed differently with every iteration, in general, for the synthetic two-dimensional example, all iterations finished with times lower than 10 minutes. This is a favorable result, as there is a high probability that the real experiment being studied for which the tool is being used can have experiments that last hours or even days.

\section{Conclusions}

Throughout the process, the appliance of Gaussian process regressions to build surrogates for objective functions proved to be an effective choice for handling uncertainty in black box systems. The methodology was proven to be correct with synthetic and real examples, building accurate Pareto fronts for the cases where it could be constructed. This fronts showed that the Gaussian process surrogates correctly describe the objectives and enable the optimization process to be performed with uncertain data.\\

The tool created was useful in the sense that it allows experimentalists to obtain an optimal set of designs to apply in their experiments, with no extra costs or inefficient use of resources. The simulation times of the optimization algorithm are reasonable compared to the time-consuming simulation codes or experiments for whom the tool was built.


\bibliographystyle{ieeetr}
\bibliography{SURF_2016}

\section{Mentor Check}

The paper was reviewed by the corresponding mentor, who only made grammar and syntax corrections. He agreed that the contents in the sections were accurate and well described for the purpose of the study. Results of real life applications are still missing due to the lack of data we need, we are waiting for the collaborating group to provide the necessary data for this purpose. The discussion and conclusion sections will be completed as soon as this data is available.

\end{document}
